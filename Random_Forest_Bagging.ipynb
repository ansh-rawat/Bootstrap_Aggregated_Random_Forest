{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# Applying Bootstrap Aggregated Random Forest using custom functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as random\n",
    "from scipy.sparse import vstack\n",
    "# Here we are using sklearn's boston dataset\n",
    "from sklearn.datasets import load_boston \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pc1htEFYuLRj",
    "outputId": "f5b60712-98b3-4cdc-b629-3546c1e3859c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "kQle3T_wuOa3",
    "outputId": "521c7bdd-5316-48d5-c534-b61d170d2c28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating samples: Randomly create 30 samples from the whole boston data points.\n",
    "\n",
    "### Creating each sample: Considering any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points.\n",
    "\n",
    "### For example: Assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly, consider we have selected [4,5,7,8,9,3] now we will replicate 4 points from this sample, consider they are [5,8,3,7] so our final sample will be [4,5,7,8,9,3,5,8,3,7].\n",
    "\n",
    "\n",
    "### Also, As a part of Bagging when we are taking the random samples we would also make sure that each of our sample will have different set of columns.\n",
    "\n",
    "### For example: Assume we have 10 columns[1,2,3,4,5,6,7,8,9,10] for the first sample we will select [3,4,5,9,1,2] and for the second sample [7,9,1,4,5,6,2] and so on. Atleast 3 feautres/columns would be there in each sample.\n",
    "\n",
    "\n",
    "### Similarly we will create 30 samples like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ph_6D2SDzz7F"
   },
   "outputs": [],
   "source": [
    "# In this function we will write code for generating 30 samples\n",
    "def generating_samples(input_data, target_data):\n",
    "    \n",
    "    # Using np.random.choice for genrating random sample.\n",
    "    # https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\n",
    "    \n",
    "    selected_rows=np.random.choice(len(input_data), 303, replace=False) # Selecting 303 unique random data points.\n",
    "    #print(len(selected_rows))\n",
    "    replicating_rows=np.random.choice(selected_rows, 203) # Replicating 203 points from 303 points which were generated above.\n",
    "    #print(len(replicating_rows))\n",
    "    selected_columns=[]\n",
    "    num=random.randint(3,12) # Selecting random number for columns with minimun 3 columns.\n",
    "    #print(num)\n",
    "    selected_columns=random.sample(range(1,13), num) # Selecting random columns.\n",
    "    #print(selected_columns)\n",
    "    sample_data=input_data[selected_rows[:,None], selected_columns] # Adding the rows and columns to a variable. \n",
    "    #print(sample_data)\n",
    "    target_sample_data=target_data[selected_rows] # Adding output variable rows similar to as sample data.\n",
    "    #print(len(target_sample_data))\n",
    "    replicated_sample_data=input_data[replicating_rows[:,None], selected_columns] # Adding repeating rows and columns.\n",
    "    #print(replicated_sample_data.shape)\n",
    "    target_replicate_sample_data=target_data[replicating_rows] # Adding output variable repeating rows similar to as sample data.\n",
    "    #print(len(target_replicate_sample_data))\n",
    "    final_sample=np.vstack((sample_data, replicated_sample_data)) # Combining the data.\n",
    "    final_target=np.vstack((target_sample_data.reshape(-1,1), target_replicate_sample_data.reshape(-1,1))) # Combining output data. \n",
    "    #print(final_sample.shape)\n",
    "    #print(final_target.shape)\n",
    "    \n",
    "    return final_sample, final_target, selected_rows, selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "### Creating 30 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples. \n",
    "# Storing these samples in a list.\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range(0,30):\n",
    "    a,b,c,d=generating_samples(x,y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are training 30 Decision Tree's with high variance for our sample data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWQp6tRwMthq"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 191.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training 30 different high variance models for our sample data.\n",
    "list_models=[]\n",
    "for i in tqdm(range(len(list_input_data))):\n",
    "    model=DecisionTreeRegressor(max_depth=None)\n",
    "    model.fit(list_input_data[i], list_output_data[i])\n",
    "    list_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "### Now we are predicting the value of each data point with our 30 models and storing the median of prediction of 30 models. Then calculating the Mean Sqaure Error from median of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWhcvMRWRA9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 506/506 [00:01<00:00, 259.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error:  0.07789946264658806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=[]\n",
    "\n",
    "# Iterating over each data point.\n",
    "for i in tqdm(range(len(x))):\n",
    "    data=x[i]\n",
    "    pred=[]\n",
    "    \n",
    "    # Making prediction on each data points with 30 models we created above.\n",
    "    for j in range(len(list_models)):\n",
    "        columns=list_selected_columns[j]\n",
    "        model=list_models[j]\n",
    "        p = model.predict(data[columns].reshape(1,-1))\n",
    "        pred.append(p)\n",
    "    \n",
    "    # Taking median of data point from each model\n",
    "    predictions.append(np.median(pred))\n",
    "\n",
    "#print(predictions)\n",
    "mse=mean_squared_error(y,predictions) # Computing Mean squre error\n",
    "print('Mean Square Error: ',mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are calculating Out of Bag Score (OOB score). \n",
    "### This is similar to above step, the only difference is that we will not make predition if our model was trained using the same data point for which we are predicting the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 506/506 [00:00<00:00, 537.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score:  14.080603198656924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Performing the same above steps but this time not to include the the points from which model was trained.\n",
    "predictions=[]\n",
    "for i in tqdm(range(len(x))):\n",
    "    data=x[i]\n",
    "    pred=[]\n",
    "    \n",
    "    for j in range(len(list_models)):\n",
    "        columns=list_selected_columns[j]\n",
    "        rows=list_selected_row[j]\n",
    "        model=list_models[j]\n",
    "        #Skipping the data points from which models was trained.\n",
    "        if i not in rows:\n",
    "            p = model.predict(data[columns].reshape(1,-1))\n",
    "            pred.append(p)\n",
    "    #print(pred)\n",
    "    predictions.append(np.median(pred))\n",
    "    \n",
    "mse=mean_squared_error(y,predictions)\n",
    "print('OOB Score: ',mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "### Repeating all the above steps again to obtain different MSE and OOB scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceW5-D88Uswi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [01:35<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "# Repeating all above steps 35 times.\n",
    "list_mse=[]\n",
    "list_oob=[]\n",
    "\n",
    "for sample in tqdm(range(35)):\n",
    "    \n",
    "    list_input_data =[]\n",
    "    list_output_data =[]\n",
    "    list_selected_row= []\n",
    "    list_selected_columns=[]\n",
    "\n",
    "    for i in range(0,30):\n",
    "        a,b,c,d=generating_samples(x,y)\n",
    "        list_input_data.append(a)\n",
    "        list_output_data.append(b)\n",
    "        list_selected_row.append(c)\n",
    "        list_selected_columns.append(d)\n",
    "        \n",
    "    list_models=[]\n",
    "    for i in range(len(list_input_data)):\n",
    "        model=DecisionTreeRegressor(max_depth=None)\n",
    "        model.fit(list_input_data[i], list_output_data[i])\n",
    "        list_models.append(model)\n",
    "        \n",
    "    predictions=[]\n",
    "    for i in range(len(x)):\n",
    "        data=x[i]\n",
    "        pred=[]\n",
    "\n",
    "        for j in range(len(list_models)):\n",
    "            columns=list_selected_columns[j]\n",
    "            model=list_models[j]\n",
    "            p = model.predict(data[columns].reshape(1,-1))\n",
    "            pred.append(p)\n",
    "\n",
    "        predictions.append(np.median(pred))\n",
    "\n",
    "    #print(predictions)\n",
    "    mse=mean_squared_error(y,predictions)\n",
    "    list_mse.append(mse)\n",
    "    \n",
    "    \n",
    "    predictions=[]\n",
    "    for i in range(len(x)):\n",
    "        data=x[i]\n",
    "        pred=[]\n",
    "\n",
    "        for j in range(len(list_models)):\n",
    "            columns=list_selected_columns[j]\n",
    "            rows=list_selected_row[j]\n",
    "            model=list_models[j]\n",
    "            if i not in rows:\n",
    "                p = model.predict(data[columns].reshape(1,-1))\n",
    "                pred.append(p)\n",
    "        #print(pred)\n",
    "        predictions.append(np.median(pred))\n",
    "\n",
    "    mse=mean_squared_error(y,predictions)\n",
    "    list_oob.append(mse)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are computing Confidence Intervals of MSE and OOB scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Mean Square Errors: (0.08597271699380007, 0.16566371321125348)\n",
      "Confidence Interval for OOB scores: (13.513575196555944, 14.537933193188813)\n"
     ]
    }
   ],
   "source": [
    "# Computing Confidence Intervals.\n",
    "# https://www.statology.org/confidence-intervals-python/\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n",
    "\n",
    "import scipy.stats as st\n",
    "# Creating 95% confidence interval for MSE\n",
    "interval_mse=st.norm.interval(alpha=0.95, loc=np.mean(list_mse), scale=st.sem(list_mse))\n",
    "print('Confidence Interval for Mean Square Errors:',interval_mse)\n",
    "\n",
    "# Creating 95% confidence interval for MSE\n",
    "interval_oob=st.norm.interval(alpha=0.95, loc=np.mean(list_oob), scale=st.sem(list_oob))\n",
    "print('Confidence Interval for OOB scores:',interval_oob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "### Using our 30 models to predict the price of house from a new data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price of the house of new data point: 18.9\n"
     ]
    }
   ],
   "source": [
    "# Repeating the same steps as done in Task 1. But this time just to predict for a single query point.\n",
    "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n",
    "pt=np.array(xq)\n",
    "ans=[]\n",
    "for i in range(len(list_models)):\n",
    "    cols=list_selected_columns[i]\n",
    "    model=list_models[i]\n",
    "    pred=model.predict(pt[cols].reshape(1,-1))\n",
    "    ans.append(pred)\n",
    "    \n",
    "print('Price of the house of new data point:',np.median(ans))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
