# Applying Bootstrap Aggregated Random Forest

Bootstrap Aggregation or Bagging is one of the Ensemble techniques in which overall variance of a model is reduced by combining several weak learners (often with low bias and high variance). 

To learn more about Bagging and other Ensembles go through the following links:

https://www.ibm.com/cloud/learn/bagging

https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205

In the .ipynb I've implemented Bootstrap Aggregated Random Forest from scratch on Boston dataset available in scikit-learn and calculated the Mean Square Error and Out of Bag score. The notebook is self explanatory and well documented with examples.
